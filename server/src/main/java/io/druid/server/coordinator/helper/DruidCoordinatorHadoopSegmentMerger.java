package io.druid.server.coordinator.helper;

import com.google.api.client.util.Maps;
import com.google.common.collect.Ordering;
import com.metamx.common.logger.Logger;
import io.druid.client.indexing.IndexingServiceClient;
import io.druid.server.coordinator.CoordinatorStats;
import io.druid.server.coordinator.DatasourceWhitelist;
import io.druid.server.coordinator.DruidCoordinatorRuntimeParams;
import io.druid.timeline.DataSegment;
import io.druid.timeline.TimelineObjectHolder;
import io.druid.timeline.VersionedIntervalTimeline;
import org.joda.time.DateTime;
import org.joda.time.Interval;

import java.util.List;
import java.util.Map;
import java.util.concurrent.atomic.AtomicReference;

/**
 */
public class DruidCoordinatorHadoopSegmentMerger implements DruidCoordinatorHelper
{

  private static final Logger log = new Logger(DruidCoordinatorHadoopSegmentMerger.class);

  private final IndexingServiceClient indexingServiceClient;
  private final AtomicReference<DatasourceWhitelist> whiteListRef;

  public DruidCoordinatorHadoopSegmentMerger(
      IndexingServiceClient indexingServiceClient,
      AtomicReference<DatasourceWhitelist> whiteListRef
  ) {
    this.indexingServiceClient = indexingServiceClient;
    this.whiteListRef = whiteListRef;
  }

  /**
   * S: the size of shard is below optimal size
   * O: the size of shard >= optimal size
   *
   * Optimal size should be configured externally, we could probably just reuse Coordinator's "mergeBytesLimit".
   *
   * Here is a timeline of segments for a specific dataSource (Note: The segment granularity for each segment could be
   * arbitrary)
   *
   * SegID:    1   2   3   4   5   6   7   8   9  10  11  12   13
   * Shard0: |_O_|_O_|_O_|_O_|_S_|_S_|_S_|_O_|_S_|_O_|_S_|_O_|_S_|__|__|__|__|__|__|__|
   * Shard1:         |_S_|                   |_S_|   |_S_|_S_|
   * Shard2:         |_S_|                   |_S_|   |_S_|
   *
   * Coordinator will periodically scan this timeline, and submit HadoopReindexTask for unbalanced sections. The end
   * result we want to achieve is that there are no shards in the * timeline that are tagged by S.
   *
   * Here is an algorithm that Coordinator could use,
   *
   * currTotalSize = 0
   * currInterval = null
   * for each segment
   *   if currInterval == null
   *     currInterval = segment.getInterval()
   *   else
   *     currInterval = currInterval.withEnd(segment.getEnd())
   *   shouldMergeNow = false
   *   for each shard of current segment
   *     if shard.getSize() < optimal size
   *       shouldMergeNow = true
   *     currTotalSize += shard.getSize()
   *
   *   if currTotalSize < optimal size
   *     // since the current segment doesn't have enough total size to make a segment
   *     // with size >= optimal size, we'll seek to merge it with the next segment in the timeline
   *     shouldMergeNow = false
   *
   *   if shouldMergeNow
   *     // Note: I still need to think of a routine that determines the segment granularity for
   *     // HadoopReindexTask so that the segments generated by it have evenly distributed sizes.
   *     submitHadoopReindexTask(dataSource, currInterval)
   *     currTotalSize = 0
   *     currInterval = null
   *
   * if currInterval != null (this check is same as if currTotalSize > 0)
   *   // To discuss: if the last chunk doesn't have enough size, what should we do about it?
   *   // Some options,
   *   // 1. We don't do anything with it, simply wait for new segments coming in, and the
   *   // next Coordinator's run will do the right thing.
   *   // 2. Find a way to merge it with a previous optimal segment
   *   // 3. ?
   */
  @Override
  public DruidCoordinatorRuntimeParams run(DruidCoordinatorRuntimeParams params)
  {
    final DatasourceWhitelist whitelist = whiteListRef.get();
    final int segmentSizeThreshold = params.getCoordinatorDynamicConfig().getMergeSegmentsLimit();

    final CoordinatorStats stats = new CoordinatorStats();
    final Map<String, VersionedIntervalTimeline<String, DataSegment>> dataSources = Maps.newHashMap();

    // Find serviced segments by using a timeline
    for (DataSegment dataSegment : params.getAvailableSegments()) {
      if (whitelist == null || whitelist.contains(dataSegment.getDataSource())) {
        VersionedIntervalTimeline<String, DataSegment> timeline = dataSources.get(dataSegment.getDataSource());
        if (timeline == null) {
          timeline = new VersionedIntervalTimeline<String, DataSegment>(Ordering.<String>natural());
          dataSources.put(dataSegment.getDataSource(), timeline);
        }
        timeline.add(
            dataSegment.getInterval(),
            dataSegment.getVersion(),
            dataSegment.getShardSpec().createChunk(dataSegment)
        );
      }
    }

    for (final Map.Entry<String, VersionedIntervalTimeline<String, DataSegment>> entry : dataSources.entrySet()) {
      final String dataSource = entry.getKey();
      final VersionedIntervalTimeline<String, DataSegment> timeline = entry.getValue();
      final List<TimelineObjectHolder<String, DataSegment>> timelineObjects = timeline.lookup(
          new Interval(new DateTime(0), new DateTime("3000-01-01"))
      );

      int currTotalSize = 0;
      Interval intervalToReindex = null;
      boolean shouldMergeNow = false;
      for (TimelineObjectHolder<String, DataSegment> objectHolder : timelineObjects) {
        final Interval currInterval = objectHolder.getInterval();
        if (intervalToReindex == null) {
          intervalToReindex = currInterval;
        } else {
          intervalToReindex = intervalToReindex.withEnd(currInterval.getEnd());
        }

        for (DataSegment segment : objectHolder.getObject().payloads()) {
          if (segment.getSize() < segmentSizeThreshold) {
            shouldMergeNow = true;
          }
          currTotalSize += segment.getSize();
        }

        if (currTotalSize >= segmentSizeThreshold) {
          if (shouldMergeNow) {
            submitHadoopReindexTask(dataSource, intervalToReindex);
          }
          currTotalSize = 0;
          intervalToReindex = null;
          shouldMergeNow = false;
        }

      }
    }

    return params.buildFromExisting().withCoordinatorStats(stats).build();
  }

  private void submitHadoopReindexTask(String dataSource, Interval intervalToReindex)
  {
    log.info("Submitting Hadoop Reindex Task for dataSource [%s] at interval [%s]", dataSource, intervalToReindex);
    indexingServiceClient.hadoopMergeSegments(dataSource, intervalToReindex);
  }

}
